What I'm thinking is that if the performance is boudned in the range .65 - .8, then we've converged to equilibrium
Plan is to use the petting zoo to train, the rl code to evaluate, lets see if it works


Info sets dict isn't properly taking in new states for some reason, this could be problem with history class, 
or could be problem with infosets dict, idk rn

Also why is a tuple still getting passed in (I think its bc we're loading the model up from the previous code which had a tuple)


[1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1
 1 1 0]

[1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.]

